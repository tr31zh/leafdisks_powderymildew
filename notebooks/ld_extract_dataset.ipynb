{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract single leaf images from sheets dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rich.progress import track\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sys.path.insert(0, os.path.join(\"..\", \"scripts\"))\n",
    "\n",
    "import gav_mildiou_const as goc\n",
    "import gav_mildiou_func as gof\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLUMNS = [\"oiv\", \"sporulation\", \"densite_sporulation\", \"necrose\", \"taille_necrose\", \"surface_necrosee\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_balance(df):\n",
    "    columns = [\n",
    "        [\"oiv\", \"\", \"\"],\n",
    "        [\"sporulation\", \"densite_sporulation\", \"\"],\n",
    "        [\"necrose\", \"taille_necrose\", \"surface_necrosee\"],\n",
    "    ]\n",
    "\n",
    "    fig = make_subplots(rows=3, cols=3, subplot_titles=np.array(columns).flatten())\n",
    "\n",
    "    for idl, l in enumerate(columns):\n",
    "        for idc, c in enumerate(l):\n",
    "            if not c:\n",
    "                continue\n",
    "            fig.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=df[c].sort_values().astype(str),\n",
    "                    texttemplate=\"%{y}\",\n",
    "                    textfont_size=20,\n",
    "                    name=c,\n",
    "                ),\n",
    "                row=idl + 1,\n",
    "                col=idc + 1,\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Value\",\n",
    "        yaxis_title=\"Count\",\n",
    "        height=800,\n",
    "        legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.99),\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.99),\n",
    "    )\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_unique_values(df):\n",
    "    for col in df.columns.to_list():\n",
    "        print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load source dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_vals = [1, 3, 5, 7, 9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = gof.build_all_dataframes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    gof.build_all_dataframes()[\"raw_merged\"]\n",
    "    .assign(rep=lambda x: x.experiment.str.split(pat=\"_\", expand=True)[1])\n",
    "    .assign(rep=lambda x: x.rep.str.replace(\"saisie\", \"NA\"))\n",
    "    .assign(\n",
    "        experiment=lambda x: x.experiment.str.split(pat=\"_\", expand=True)[0],\n",
    "        year=lambda x: x.experiment.str.lower()\n",
    "        .str.split(pat=\"exp\", expand=True)[1]\n",
    "        .str.split(pat=\"dm\", expand=True)[0]\n",
    "        .astype(int),\n",
    "    )\n",
    "    .assign(\n",
    "        necrose=lambda x: x.necrose.replace(r\"^([A-Za-z]|_)+$\", np.NaN, regex=True),\n",
    "        oiv=lambda x: x.oiv.replace(r\"^([A-Za-z]|_)+$\", np.NaN, regex=True),\n",
    "        sporulation=lambda x: x.sporulation.replace(\n",
    "            r\"^([A-Za-z]|_)+$\", np.NaN, regex=True\n",
    "        ),\n",
    "        surface_necrosee=lambda x: x.surface_necrosee.replace(\n",
    "            r\"^([A-Za-z]|_)+$\", np.NaN, regex=True\n",
    "        ),\n",
    "        densite_sporulation=lambda x: x.densite_sporulation.replace(\n",
    "            r\"^([A-Za-z]|_)+$\", np.NaN, regex=True\n",
    "        ),\n",
    "        taille_necrose=lambda x: x.taille_necrose.replace(\n",
    "            r\"^([A-Za-z]|_)+$\", np.NaN, regex=True\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "df = df[df.year.isin([20, 21, 22])]\n",
    "\n",
    "def try_for_number(val):\n",
    "    try:\n",
    "        int(val)\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        return int(val)\n",
    "    try:\n",
    "        float(val)\n",
    "    except:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        try:\n",
    "            return round(float(val))\n",
    "        except:\n",
    "            return np.NaN\n",
    "\n",
    "\n",
    "for col in DATA_COLUMNS:\n",
    "    df[col] = df[col].apply(lambda x: try_for_number(x))\n",
    "\n",
    "\n",
    "for k, v in {\n",
    "    \"oiv\": allowed_vals,\n",
    "    \"sporulation\": [0, 1],\n",
    "    \"densite_sporulation\": allowed_vals,\n",
    "    \"necrose\": [0, 1],\n",
    "    \"taille_necrose\": allowed_vals,\n",
    "    \"surface_necrosee\": allowed_vals,\n",
    "}.items():\n",
    "    df[k] = df[k].apply(lambda x: x if x in v else np.NaN)\n",
    "\n",
    "df = (\n",
    "    df.assign(\n",
    "        necrose=lambda x: x.necrose.astype(\"Int64\"),\n",
    "        oiv=lambda x: x.oiv.astype(\"Int64\"),\n",
    "        sporulation=lambda x: x.sporulation.astype(\"Int64\"),\n",
    "        surface_necrosee=lambda x: x.surface_necrosee.astype(\"Int64\"),\n",
    "        densite_sporulation=lambda x: x.densite_sporulation.astype(\"Int64\"),\n",
    "        taille_necrose=lambda x: x.taille_necrose.astype(\"Int64\"),\n",
    "        dai=lambda x: x.sheet.str.extract(\"(\\d+)\"),\n",
    "    )\n",
    "    .drop_duplicates()\n",
    "    .sort_values([\"experiment\", \"image_name\", \"ligne\", \"colonne\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "# df = gof.invert_axis(df, 0)\n",
    "\n",
    "df\n",
    "\n",
    "plot_balance(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.oiv.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_unique_values(df[DATA_COLUMNS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "vals = [0, 1, 3, 5, 7, 9]\n",
    "sample_size = 3\n",
    "for year in track(df.year.unique()):\n",
    "    # Numeric Variables\n",
    "    for var in [\"densite_sporulation\", \"taille_necrose\", \"surface_necrosee\", \"oiv\"]:\n",
    "        for val in vals:\n",
    "            tmp_df = df[(df.year == year) & (df[var] == val)]\n",
    "            data.append(tmp_df.sample(n=min(sample_size, tmp_df.shape[0])))\n",
    "    # Binary varaibles\n",
    "    for var in [\n",
    "        \"sporulation\",\n",
    "        \"necrose\",\n",
    "    ]:\n",
    "        for val in [0, 1]:\n",
    "            tmp_df = df[(df.year == year) & (df[var] == val)]\n",
    "            data.append(tmp_df.sample(n=min(sample_size, tmp_df.shape[0])))\n",
    "    # Trash\n",
    "    # for var in [\n",
    "        # \"densite_sporulation\",\n",
    "        # \"taille_necrose\",\n",
    "        # \"surface_necrosee\",\n",
    "        # \"oiv\",\n",
    "    # ]:\n",
    "    #     tmp_df = df[(df.year == year) & (~df[var].isin(vals))]\n",
    "    #     data.append(tmp_df.sample(n=min(sample_size, tmp_df.shape[0])))\n",
    "    # for var in [\n",
    "    #     \"sporulation\",\n",
    "    #     \"necrose\",\n",
    "    # ]:\n",
    "    #     tmp_df = df[(df.year == year) & (~df[var].isin([0, 1]))]\n",
    "    #     data.append(tmp_df.sample(n=min(sample_size, tmp_df.shape[0])))\n",
    "\n",
    "\n",
    "df_ld = (\n",
    "    pd.concat(data)\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .assign(exp_folder=lambda x: \"EXP-20\" + x.year.astype(str))\n",
    ")\n",
    "\n",
    "plot_balance(df_ld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ld.to_csv(Path.cwd().parent.joinpath(goc.dataframes_path, \"ld_dataset_ilastik_train.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing dataset dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(str(Path.cwd().parent.joinpath(goc.dataframes_path, \"ld_dataset_ilastik_train.csv\")), sep=\",\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_balance(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sheet.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[d.sheet == \"Feuil1\", \"sheet\"] = \"fichier_total\"\n",
    "d.loc[d.sheet == \"fichier total\", \"sheet\"] = \"fichier_total\"\n",
    "\n",
    "d.sheet.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serach folders related to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = Path.cwd().parent.joinpath(\"data_in\", \"gav_phenotypage\")\n",
    "root_folder.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ld_sheet(exp_year_folder, experiment, rep, dai, image_name) -> Path | str:\n",
    "    fld_candidates = [\n",
    "        f for f in root_folder.joinpath(exp_year_folder).glob(f\"*{experiment}*\")\n",
    "    ]\n",
    "    if len(fld_candidates) == 0:\n",
    "        return \"No match for experiment folder\"\n",
    "    elif len(fld_candidates) > 1:\n",
    "        return f\"Ambiguous experiment folder, {len(fld_candidates)} found\"\n",
    "\n",
    "    fld_candidate = fld_candidates[0]\n",
    "    if fld_candidate.is_dir() is False:\n",
    "        return \"Experiment folder is not folder\"\n",
    "\n",
    "    name_parts = image_name.replace(\"-\", \"_\").split(\"_\")\n",
    "    if len(name_parts[-1]) < 3:\n",
    "        nparts = name_parts[:-1]\n",
    "        end = name_parts[-1]\n",
    "        image_name = \"_\".join(name_parts[:-1]) + \"_\" + end[0] + \"0\" + end[1]\n",
    "\n",
    "    if len(name_parts) == 3:\n",
    "        e, i, p = image_name.replace(\"-\", \"_\").split(\"_\")\n",
    "        r_img_name = (\n",
    "            f\"{e}_{i}_T{int(dai) if type(dai) == int or type(dai) == float else 0}_{p}\"\n",
    "        )\n",
    "    else:\n",
    "        r_img_name = image_name.replace(\"-\", \"_\")\n",
    "    candidates = [\n",
    "        fc\n",
    "        for fc in fld_candidate.glob(\n",
    "            f\"**/*{r_img_name.replace('i', '?').replace('I', '?')}.*\"\n",
    "        ) if fc.suffix in [\".JPG\", \".jpg\"]\n",
    "    ]\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        return \"No image matches name\"\n",
    "    elif len(candidates) == 1:\n",
    "        return candidates[0]\n",
    "    else:\n",
    "        return f\"Ambiguous image query\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sheet_from_row(row) -> Path | str:\n",
    "    return get_ld_sheet(\n",
    "        exp_year_folder=row.exp_folder.to_list()[0],\n",
    "        experiment=row.experiment.to_list()[0],\n",
    "        rep=row.rep.to_list()[0],\n",
    "        dai=row.dai.to_list()[0],\n",
    "        image_name=row.image_name.to_list()[0],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graber = d[[\"exp_folder\", \"experiment\", \"rep\", \"dai\", \"image_name\"]].drop_duplicates().reset_index()\n",
    "graber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_data = {\n",
    "    \"exp_folder\": [],\n",
    "    \"experiment\": [],\n",
    "    \"rep\": [],\n",
    "    \"dai\": [],\n",
    "    \"image_name\": [],\n",
    "    \"file_path\": [],\n",
    "}\n",
    "\n",
    "for row in tqdm([row for _, row in d.iterrows()]):\n",
    "    try:\n",
    "        try_data[\"exp_folder\"].append(row.exp_folder)\n",
    "        try_data[\"experiment\"].append(row.experiment)\n",
    "        try_data[\"rep\"].append(row.rep)\n",
    "        try_data[\"dai\"].append(row.dai)\n",
    "        try_data[\"image_name\"].append(row.image_name)\n",
    "        try_data[\"file_path\"].append(\n",
    "            str(\n",
    "                get_ld_sheet(\n",
    "                    exp_year_folder=row.exp_folder,\n",
    "                    experiment=row.experiment,\n",
    "                    rep=row.rep,\n",
    "                    dai=row.dai,\n",
    "                    image_name=row.image_name,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        try_data[\"file_path\"].append(str(e))\n",
    "\n",
    "\n",
    "try_outcome = pd.DataFrame(data=try_data)\n",
    "try_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_outcomes = {k:try_outcome[try_outcome.file_path == k ]  for k in try_outcome[~try_outcome.file_path.str.contains(\"/\")].file_path.unique()}\n",
    "bad_outcomes.keys()\n",
    "# try_outcome.file_path.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimn = bad_outcomes[\"No image matches name\"].sort_values([\"experiment\", \"image_name\"]).drop_duplicates().reset_index(drop=True)\n",
    "nimn.experiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_outcomes = try_outcome[try_outcome.file_path.str.contains(\"/\")]\n",
    "good_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for file_ in tqdm(good_outcomes.file_path.to_list()):\n",
    "    shutil.copyfile(file_, Path.cwd().parent.joinpath(\"data_in\", \"images\", \"ld_copied\", Path(file_).name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_name == \"Exp22DM08_inoc2_T5_P29\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57ea4112c076accd34380d1fc13840c87329161a9b2286676849023bcb84b091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
