{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Sankey(\n",
    "            node=dict(\n",
    "                label=[\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"],\n",
    "            ),\n",
    "            link=dict(\n",
    "                # indices correspond to labels, eg A1, A2, A2, B1, ...\n",
    "                source=[0, 1, 0, 2, 3, 3],\n",
    "                target=[2, 3, 3, 4, 4, 5],\n",
    "                value=[1, 2, 3, 4, 5, 6],\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_layout(title_text=\"Basic Sankey Diagram\", font_size=10)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import urllib, json\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/plotly/plotly.js/master/test/image/mocks/sankey_energy.json'\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "\n",
    "# override gray link colors with 'source' colors\n",
    "opacity = 0.4\n",
    "# change 'magenta' to its 'rgba' value to add opacity\n",
    "data['data'][0]['node']['color'] = ['rgba(255,0,255, 0.8)' if color == \"magenta\" else color for color in data['data'][0]['node']['color']]\n",
    "data['data'][0]['link']['color'] = [data['data'][0]['node']['color'][src].replace(\"0.8\", str(opacity))\n",
    "                                    for src in data['data'][0]['link']['source']]\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    valueformat = \".0f\",\n",
    "    valuesuffix = \"TWh\",\n",
    "    # Define nodes\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 15,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label =  data['data'][0]['node']['label'],\n",
    "      color =  data['data'][0]['node']['color']\n",
    "    ),\n",
    "    # Add links\n",
    "    link = dict(\n",
    "      source =  data['data'][0]['link']['source'],\n",
    "      target =  data['data'][0]['link']['target'],\n",
    "      value =  data['data'][0]['link']['value'],\n",
    "      label =  data['data'][0]['link']['label'],\n",
    "      color =  data['data'][0]['link']['color']\n",
    "))])\n",
    "\n",
    "fig.update_layout(title_text=\"Energy forecast for 2050<br>Source: Department of Energy & Climate Change, Tom Counsell via <a href='https://bost.ocks.org/mike/sankey/'>Mike Bostock</a>\",\n",
    "                  font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['data'][0]['link']['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "\n",
    "print(f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(\n",
    "            data,\n",
    "            estimator[-1].labels_,\n",
    "            metric=\"euclidean\",\n",
    "            sample_size=300,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\n",
    "        \"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
    "    )\n",
    "    print(formatter_result.format(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(82 * \"_\")\n",
    "print(\"init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\")\n",
    "\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_digits, n_init=4, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
    "\n",
    "kmeans = KMeans(init=\"random\", n_clusters=n_digits, n_init=4, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"random\", data=data, labels=labels)\n",
    "\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "kmeans = KMeans(init=pca.components_, n_clusters=n_digits, n_init=1)\n",
    "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=data, labels=labels)\n",
    "\n",
    "print(82 * \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_digits, n_init=4)\n",
    "kmeans.fit(reduced_data)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "# plt.imshow(\n",
    "#     Z,\n",
    "#     interpolation=\"nearest\",\n",
    "#     extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "#     cmap=plt.cm.Paired,\n",
    "#     aspect=\"auto\",\n",
    "#     origin=\"lower\",\n",
    "# )\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-means clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centroids are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# create dataset\n",
    "X, y = make_blobs(\n",
    "   n_samples=150, n_features=2,\n",
    "   centers=3, cluster_std=0.5,\n",
    "   shuffle=True, random_state=0\n",
    ")\n",
    "\n",
    "# plot\n",
    "plt.scatter(\n",
    "   X[:, 0], X[:, 1],\n",
    "   c='white', marker='o',\n",
    "   edgecolor='black', s=50\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(\n",
    "    n_clusters=3, init='random',\n",
    "    n_init=10, max_iter=300, \n",
    "    tol=1e-04, random_state=0\n",
    ")\n",
    "y_km = km.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 3 clusters\n",
    "plt.scatter(\n",
    "    X[y_km == 0, 0], X[y_km == 0, 1],\n",
    "    s=50, c='lightgreen',\n",
    "    marker='s', edgecolor='black',\n",
    "    label='cluster 1'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    X[y_km == 1, 0], X[y_km == 1, 1],\n",
    "    s=50, c='orange',\n",
    "    marker='o', edgecolor='black',\n",
    "    label='cluster 2'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    X[y_km == 2, 0], X[y_km == 2, 1],\n",
    "    s=50, c='lightblue',\n",
    "    marker='v', edgecolor='black',\n",
    "    label='cluster 3'\n",
    ")\n",
    "\n",
    "# plot the centroids\n",
    "plt.scatter(\n",
    "    km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n",
    "    s=250, marker='*',\n",
    "    c='red', edgecolor='black',\n",
    "    label='centroids'\n",
    ")\n",
    "plt.legend(scatterpoints=1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris['feature_names'])\n",
    "#print(X)\n",
    "data = X[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)']]\n",
    "\n",
    "sse = {}\n",
    "for k in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(data)\n",
    "    data[\"clusters\"] = kmeans.labels_\n",
    "    #print(data[\"clusters\"])\n",
    "    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# Generating the sample data from make_blobs\n",
    "# This particular setting has one distinct cluster and 3 clusters placed close\n",
    "# together.\n",
    "X, y = make_blobs(\n",
    "    n_samples=500,\n",
    "    n_features=2,\n",
    "    centers=4,\n",
    "    cluster_std=1,\n",
    "    center_box=(-10.0, 10.0),\n",
    "    shuffle=True,\n",
    "    random_state=1,\n",
    ")  # For reproducibility\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        n_clusters,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(\n",
    "        X[:, 0], X[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(\n",
    "        centers[:, 0],\n",
    "        centers[:, 1],\n",
    "        marker=\"o\",\n",
    "        c=\"white\",\n",
    "        alpha=1,\n",
    "        s=200,\n",
    "        edgecolor=\"k\",\n",
    "    )\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "        % n_clusters,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    " \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    " \n",
    "#Load Data\n",
    "data = load_digits().data\n",
    "pca = PCA(2)\n",
    " \n",
    "#Transform the data\n",
    "df = pca.fit_transform(data)\n",
    " \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required module\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "#Initialize the class object\n",
    "kmeans = KMeans(n_clusters= 10)\n",
    " \n",
    "#predict the labels of clusters.\n",
    "label = kmeans.fit_predict(df)\n",
    " \n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#filter rows of original data\n",
    "filtered_label0 = df[label == 0]\n",
    " \n",
    "#plotting the results\n",
    "plt.scatter(filtered_label0[:,0] , filtered_label0[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter rows of original data\n",
    "filtered_label2 = df[label == 2]\n",
    " \n",
    "filtered_label8 = df[label == 8]\n",
    " \n",
    "#Plotting the results\n",
    "plt.scatter(filtered_label2[:,0] , filtered_label2[:,1] , color = 'red')\n",
    "plt.scatter(filtered_label8[:,0] , filtered_label8[:,1] , color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting unique labels\n",
    " \n",
    "u_labels = np.unique(label)\n",
    " \n",
    "#plotting the results:\n",
    " \n",
    "for i in u_labels:\n",
    "    plt.scatter(df[label == i , 0] , df[label == i , 1] , label = i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the Centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "u_labels = np.unique(label)\n",
    " \n",
    "#plotting the results:\n",
    " \n",
    "for i in u_labels:\n",
    "    plt.scatter(df[label == i , 0] , df[label == i , 1] , label = i)\n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    " \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    " \n",
    "#Load Data\n",
    "data = load_digits().data\n",
    "pca = PCA(2)\n",
    " \n",
    "#Transform the data\n",
    "df = pca.fit_transform(data)\n",
    " \n",
    "#Import KMeans module\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "#Initialize the class object\n",
    "kmeans = KMeans(n_clusters= 10)\n",
    " \n",
    "#predict the labels of clusters.\n",
    "label = kmeans.fit_predict(df)\n",
    " \n",
    "#Getting unique labels\n",
    "u_labels = np.unique(label)\n",
    " \n",
    "#plotting the results:\n",
    "for i in u_labels:\n",
    "    plt.scatter(df[label == i , 0] , df[label == i , 1] , label = i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "mesh_size = .02\n",
    "margin = 0.25\n",
    "\n",
    "# Load and split data\n",
    "X, y = make_moons(noise=0.3, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y.astype(str), test_size=0.25, random_state=0)\n",
    "\n",
    "# Create a mesh grid on which we will run our model\n",
    "x_min, x_max = X[:, 0].min() - margin, X[:, 0].max() + margin\n",
    "y_min, y_max = X[:, 1].min() - margin, X[:, 1].max() + margin\n",
    "xrange = np.arange(x_min, x_max, mesh_size)\n",
    "yrange = np.arange(y_min, y_max, mesh_size)\n",
    "xx, yy = np.meshgrid(xrange, yrange)\n",
    "\n",
    "# Create classifier, run predictions on grid\n",
    "clf = KNeighborsClassifier(15, weights='uniform')\n",
    "clf.fit(X, y)\n",
    "Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "trace_specs = [\n",
    "    [X_train, y_train, '0', 'Train', 'square'],\n",
    "    [X_train, y_train, '1', 'Train', 'circle'],\n",
    "    [X_test, y_test, '0', 'Test', 'square-dot'],\n",
    "    [X_test, y_test, '1', 'Test', 'circle-dot']\n",
    "]\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter(\n",
    "        x=X[y==label, 0], y=X[y==label, 1],\n",
    "        name=f'{split} Split, Label {label}',\n",
    "        mode='markers', marker_symbol=marker\n",
    "    )\n",
    "    for X, y, label, split, marker in trace_specs\n",
    "])\n",
    "fig.update_traces(\n",
    "    marker_size=12, marker_line_width=1.5,\n",
    "    marker_color=\"lightyellow\"\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Contour(\n",
    "        x=xrange,\n",
    "        y=yrange,\n",
    "        z=Z,\n",
    "        showscale=False,\n",
    "        colorscale='RdBu',\n",
    "        opacity=0.4,\n",
    "        name='Score',\n",
    "        hoverinfo='skip'\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "[(i, j )for i, j in itertools.product([1, 2, 3], [1, 2, 3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p for p in itertools.permutations([\"taille_necrose\", \"surface_necrosee\", \"densite_sporulation\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage.io as skio\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(\"..\", \"data_in\", \"images\", \"oiv_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    os.path.join(img_path, f)\n",
    "    for f in [\n",
    "        \"smp_oiv_1.png\",\n",
    "        \"smp_oiv_3.png\",\n",
    "        \"smp_oiv_5.png\",\n",
    "        \"smp_oiv_57.png\",\n",
    "        \"smp_oiv_7.png\",\n",
    "        \"smp_oiv_7_tn_diff.png\",\n",
    "        \"smp_oiv_9.png\",\n",
    "        \"smp_oiv_9_adp.png\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# px.imshow(skio.imread(files[0]))\n",
    "# return [os.path.isfile(f) for f in files]\n",
    "titles = [\n",
    "    \"OIV 1\",\n",
    "    \"OIV 3\",\n",
    "    \"OIV 5\",\n",
    "    \"OIV 5 or 7\",\n",
    "    \"OIV 7\",\n",
    "    \"OIV 7, different necrose size\",\n",
    "    \"OIV 9\",\n",
    "    \"OIV 9 bis\",\n",
    "]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=8, subplot_titles=np.array(titles).flatten())\n",
    "\n",
    "for idx, f in enumerate(files):\n",
    "    fig.add_trace(\n",
    "        go.Image(z=skio.imread(f)),\n",
    "        row=1,\n",
    "        col=idx + 1,\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(showticklabels = False).update_yaxes(showticklabels = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57ea4112c076accd34380d1fc13840c87329161a9b2286676849023bcb84b091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
